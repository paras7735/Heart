{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T10:53:56.551386Z",
     "start_time": "2018-10-23T10:53:42.831262Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ggplot\\utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model,datasets,tree\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from ggplot import *\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats.stats import pearsonr \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import FCBF\n",
    "import CFS\n",
    "import reliefF\n",
    "from id3 import Id3Estimator\n",
    "from scipy import optimize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T10:54:07.288289Z",
     "start_time": "2018-10-23T10:53:56.554370Z"
    }
   },
   "outputs": [],
   "source": [
    "iri = pd.read_excel('1_YEAR_2.FOLD.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T10:54:14.376305Z",
     "start_time": "2018-10-23T10:54:07.291254Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 10893\n",
      "Class 1: 1455\n",
      "Proportion: 7.48659793814433 : 1\n"
     ]
    }
   ],
   "source": [
    "iris=iri #.select_dtypes(['number'])\n",
    "for column in iris.columns:\n",
    "    if iris[column].dtype == type(object):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        iris[column] = le.fit_transform(iris[column])\n",
    "iri2=iris\n",
    "#X=iri2.loc[:,['LIFE_SUP_TCR','HGT_CM_TCR','DAYS_STAT1','GENDER_MATCH','DEATH_MECH_DON','AGE','HLAMAT','AGE_MATCH_LEVEL','PROC_TY_HR','EDUCATION','SHARE_TY','GENDER','IMPL_DEFIBRIL','PULM_INF_DON','TATTOOS','ETHCAT_MATCH','AGE_DON','ABO','GENDER_DON','HIST_CIG_DON','DAYS_STAT1A','LIFE_SUP_TRR','MED_COND_TRR','CORONARY_ANGIO','VENT_SUPPORT_AFTER_LIST','ETHCAT_DON','HIST_OTH_DRUG_DON','DIAB','ABO_MAT','INIT_STAT','DDAVP_DON','END_STAT','DEATH_CIRCUM_DON','PRI_PAYMENT_TCR','ETHCAT','PRI_PAYMENT_TRR','REGION','ABO_DON','DIAG','THORACIC_DGN','FUNC_STAT_TCR','TCR_DGN','FUNC_STAT_TRR']]\n",
    "#Uncoment for features as in spss\n",
    "cols=[\"ABO\",\"ABO_DON\",\"ABO_MAT\",\"AGE\",\"AGE_DON\",\"AGE_MATCH_LEVEL\",\"CORONARY_ANGIO\",\"DAYS_STAT1\",\"DAYS_STAT1A\",\"DAYS_STAT2\",\"DDAVP_DON\",\"DEATH_CIRCUM_DON\",\"DEATH_MECH_DON\",\"DIAB\",\"DIAG\",\"DON_RETYP\",\"EDUCATION\",\"END_STAT\",\"ETHCAT\",\"ETHCAT_MATCH\",\"FUNC_STAT_TCR\",\"FUNC_STAT_TRR\",\"GENDER\",\"GENDER_DON\",\"GENDER_MATCH\",\"HEP_C_ANTI_DON\",\"HIST_CIG_DON\",\"HIST_OTH_DRUG_DON\",\"HLAMAT\",\"IMPL_DEFIBRIL\",\"INIT_STAT\",\"INOTROPES_TCR\",\"LIFE_SUP_TCR\",\"MED_COND_TRR\",\"PRI_PAYMENT_TCR\",\"PRI_PAYMENT_TRR\",\"PROC_TY_HR\",\"REGION\",\"SHARE_TY\",\"TCR_DGN\",\"THORACIC_DGN\",\"VENT_SUPPORT_AFTER_LIST\"]\n",
    "#X=iri2.loc[:,cols]\n",
    "#uncoment for all features - gtime\n",
    "iri3=iri2.drop(labels=['GSTATUS','GTIME'], axis=1)\n",
    "X=iri3\n",
    "Y = iri2.GSTATUS.values\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "#X= SelectKBest(chi2, k=1).fit_transform(X, Y)\n",
    "#import seaborn as sns\n",
    "corr = X.corr()\n",
    "#corr= pearsonr(X,X)\n",
    "col=list(X.columns.values)\n",
    "col2=col #[:-2]\n",
    "#fig, ax = plt.subplots()\n",
    "# the size of A4 paper\n",
    "#fig.set_size_inches(40, 30)\n",
    "#sns.heatmap(corr, \n",
    "#        xticklabels=col2,\n",
    "#        yticklabels=col2,ax=ax)\n",
    "#fig.savefig('example.png')\n",
    "unique, counts = np.unique(Y, return_counts=True)\n",
    "target_count=dict(zip(unique, counts))\n",
    "print('Class 0:', target_count[0])\n",
    "print('Class 1:', target_count[1])\n",
    "print('Proportion:', target_count[0] / target_count[1], ': 1')\n",
    "#dictionary = plt.figure()\n",
    "#plt.bar(range(len(target_count)), target_count.values(), align='center')\n",
    "#plt.xticks(range(len(target_count)), target_count.keys())\n",
    "#plt.show()\n",
    "#X=X.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T10:54:14.383300Z",
     "start_time": "2018-10-23T10:54:14.379306Z"
    }
   },
   "outputs": [],
   "source": [
    "#pd.plotting.scatter_matrix(X)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T10:54:14.402290Z",
     "start_time": "2018-10-23T10:54:14.386299Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_threshold(threshold,tpr,fpr,thresholds):\n",
    "    seng=tpr[thresholds > threshold][-1]\n",
    "    speg=1 - fpr[thresholds > threshold][-1]\n",
    "    print('Sensitivity:', seng)\n",
    "    print('Specificity:', speg)\n",
    "    return seng,speg\n",
    "def acuracy_auc_and_confusionmatrix(model,x_test,y_test,graph):\n",
    "    test_set_predictions = [model.predict(x_test[i].reshape((1,x_test.shape[1]))) for i in range(x_test.shape[0])]\n",
    "    acg=accuracy_score(y_test, test_set_predictions)\n",
    "    print(\"accuracy is : \",acg)\n",
    "    print(confusion_matrix(y_test, test_set_predictions))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, test_set_predictions)\n",
    "    if graph==1:\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.title('ROC curve for diabetes classifier')\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.grid(True)\n",
    "    seng,speg=evaluate_threshold(0.5,tpr,fpr,thresholds)\n",
    "    aucg=metrics.roc_auc_score(y_test, test_set_predictions)\n",
    "    print(aucg)\n",
    "    return acg,aucg,seng,speg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T10:54:14.463254Z",
     "start_time": "2018-10-23T10:54:14.406288Z"
    }
   },
   "outputs": [],
   "source": [
    "def nocross(X,Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=10)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "def smotefun(X_train,Y_train):\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train, Y_train = sm.fit_sample(X_train, Y_train)\n",
    "    return X_train, Y_train\n",
    "def rus(X_train,Y_train):\n",
    "    sm = RandomUnderSampler(random_state=2,)\n",
    "    X_train, Y_train = sm.fit_sample(X_train, Y_train)\n",
    "    return X_train, Y_train\n",
    "def normalize(X_train,X_test):\n",
    "    X_train = preprocessing.normalize(X_train, norm='l2')\n",
    "    X_test = preprocessing.normalize(X_test, norm='l2')\n",
    "    return X_train, X_test\n",
    "def standardise(X_train,X_test):\n",
    "    X_train = preprocessing.scale(X_train)\n",
    "    X_test = preprocessing.scale(X_test)\n",
    "    return X_train, X_test\n",
    "def fitpredict(X_train,Y_train,mod,X_test,Y_test,graph):\n",
    "    mod.fit(X_train,Y_train) \n",
    "    #export_graphviz(mod, 'tree3.dot', col)\n",
    "    #rfe = RFE(estimator=mod, n_features_to_select=5, step=1)\n",
    "    #rfe = rfe.fit(X_train, Y_train)\n",
    "    #print('Chosen best 5 feature by rfe:',rfe.support_)\n",
    "    acg,aucg,seng,speg=acuracy_auc_and_confusionmatrix(mod,X_test,Y_test,graph)\n",
    "    return acg,aucg,seng,speg\n",
    "def modelselector(model):\n",
    "    if model==0:\n",
    "        print(\"LR\")\n",
    "        mod = linear_model.LogisticRegression(C=1e5) #C is the inverse of the regularization factor\n",
    "    if model==1:\n",
    "        print(\"ANN\")\n",
    "        mod = MLPClassifier(hidden_layer_sizes=(30,30,30),max_iter=200000)\n",
    "    if model==2:\n",
    "        print(\"CRT\")\n",
    "        mod = DecisionTreeClassifier(criterion = \"gini\")\n",
    "    if model==3:\n",
    "        print(\"SVCL\")\n",
    "        mod = SVC(kernel='linear')  \n",
    "    if model==4:\n",
    "        print(\"SVCP\")\n",
    "        mod = SVC(kernel='poly', degree=2)    \n",
    "    if model==5:\n",
    "        print(\"Random Forest\")\n",
    "        mod = RandomForestClassifier(random_state=43)\n",
    "    if model==6:\n",
    "        print(\"DT\")\n",
    "        mod = Id3Estimator()\n",
    "    return mod\n",
    "def stdselector(X_train,X_test,norstd):\n",
    "    if norstd==1:\n",
    "        print(\"Normalize\")\n",
    "        X_train,X_test=normalize(X_train,X_test)\n",
    "    if norstd==2:\n",
    "        print(\"Standardize\")\n",
    "        X_train,X_test=standardise(X_train,X_test)    \n",
    "    return X_train,X_test\n",
    "def smoteselector(X_train,X_test,Y_train,Y_test,smote):\n",
    "    if smote==1:\n",
    "        print(\"Smote\")\n",
    "        X_train, Y_train=smotefun(X_train,Y_train)\n",
    "    if smote==2:\n",
    "        print(\"RUS\")\n",
    "        X_train, Y_train=rus(X_train,Y_train)\n",
    "    return X_train,X_test,Y_train,Y_test\n",
    "\n",
    "def crosse(X,Y,norstd,smote,featureselect,model,graph) :\n",
    "    X=X.values\n",
    "    ac=[]\n",
    "    auc=[]\n",
    "    sen=[]\n",
    "    spe=[]\n",
    "    kf = model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_index, val_index in kf.split(X, Y):\n",
    "        X_train, X_test = X[train_index], X[val_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[val_index]\n",
    "        X_train,X_test=stdselector(X_train,X_test,norstd)\n",
    "        X_train,X_test,Y_train,Y_test=smoteselector(X_train,X_test,Y_train,Y_test,smote)\n",
    "        X_train,X_test=featureselector(featureselect,X_train,Y_train,X_test)\n",
    "        mod=modelselector(model)\n",
    "        acg,aucg,seng,speg=fitpredict(X_train,Y_train,mod,X_test,Y_test,graph)\n",
    "        ac.append(acg)\n",
    "        auc.append(aucg)\n",
    "        sen.append(seng)\n",
    "        spe.append(speg)\n",
    "    print(\"10foldcrossvalidation mean AUC\",np.mean(auc))\n",
    "    print(\"10foldcrossvalidation mean ACCURACY\",np.mean(ac))\n",
    "    print(\"10foldcrossvalidation mean SENSITIVITY\",np.mean(sen))\n",
    "    print(\"10foldcrossvalidation mean SPECIFICITY\",np.mean(spe))\n",
    "def fcb(X_train,Y_train,X_test):\n",
    "    #X_train=X_train.values\n",
    "    #X_test=X_test.values\n",
    "    idx =FCBF.fcbf(X_train,Y_train)\n",
    "    for i in idx[0]:\n",
    "        print('Using ',col[i])\n",
    "    features = X_train[:, idx[0]]\n",
    "    features2 = X_test[:, idx[0]]\n",
    "    return features,features2\n",
    "def cf(X_train,Y_train,X_test):\n",
    "    #X_train=X_train.values\n",
    "    #X_test=X_test.values\n",
    "    idx =CFS.cfs(X_train,Y_train)\n",
    "    for i in idx:\n",
    "        print('Using ',col[i])\n",
    "    features = X_train[:, idx]\n",
    "    features2 = X_test[:, idx]\n",
    "    return features,features2\n",
    "def rel(X_train,Y_train,X_test):\n",
    "    score = reliefF.reliefF(X_train,Y_train)\n",
    "    idx = reliefF.feature_ranking(score)\n",
    "    for i in idx:\n",
    "        print('Using ',col[i])\n",
    "    features = X_train[:, idx]\n",
    "    features2 = X_test[:, idx]\n",
    "    return features,features2\n",
    "def sa(X_train,Y_train,X_test):\n",
    "    #X_train=X_train.values\n",
    "    #X_test=X_test.values\n",
    "    pca = PCA(n_components=5)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.fit_transform(X_test)\n",
    "    pca_result=X_train\n",
    "    df=pd.DataFrame(pca_result)\n",
    "    scatter_matrix(df, alpha=0.2, figsize=(6, 6), diagonal='kde')\n",
    "    print(X_test.shape)\n",
    "    features = X_train\n",
    "    features2 = X_test\n",
    "    return features,features2    \n",
    "def pc(X_train,Y_train,X_test):\n",
    "    #X_train=X_train.values\n",
    "    #X_test=X_test.values\n",
    "    pca = PCA(n_components=5)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.fit_transform(X_test)\n",
    "    pca_result=X_train\n",
    "    df=pd.DataFrame(pca_result)\n",
    "    scatter_matrix(df, alpha=0.2, figsize=(6, 6), diagonal='kde')\n",
    "    print(X_test.shape)\n",
    "    features = X_train\n",
    "    features2 = X_test\n",
    "    return features,features2    \n",
    "def featureselector(featureselect,X_train,Y_train,X_test):\n",
    "    if featureselect==1:\n",
    "        print(\"FCBF\")\n",
    "        X_train,X_test=fcb(X_train,Y_train,X_test)\n",
    "    if featureselect==2:\n",
    "        print(\"CFS\")\n",
    "        X_train,X_test=cf(X_train,Y_train,X_test)\n",
    "    if featureselect==3:\n",
    "        print(\"ReliefF\")\n",
    "        X_train,X_test=rel(X_train,Y_train,X_test)\n",
    "    if featureselect==4:\n",
    "        print(\"PCA\")\n",
    "        X_train,X_test=pc(X_train,Y_train,X_test)\n",
    "    if featureselect==5:\n",
    "        print(\"Simul\")\n",
    "        X_train,X_test=sa(X_train,Y_train,X_test)\n",
    "    return X_train,X_test\n",
    "def mod(cross,norstd,smote,featureselect,model,graph):\n",
    "    if cross==0:\n",
    "        X_train, X_test, Y_train, Y_test=nocross(X,Y)\n",
    "        X_train,X_test=stdselector(X_train,X_test,norstd)\n",
    "        X_train,X_test,Y_train,Y_test=smoteselector(X_train,X_test,Y_train,Y_test,smote)\n",
    "        X_train,X_test=featureselector(featureselect,X_train,Y_train,X_test)\n",
    "        mod=modelselector(model)\n",
    "        fitpredict(X_train,Y_train,mod,X_test,Y_test,graph)\n",
    "    if cross==1:\n",
    "        print(\"10 Cross\")\n",
    "        crosse(X,Y,norstd,smote,featureselect,model,graph)\n",
    "def pca(comp):\n",
    "    a=PCA(n_components=comp)\n",
    "    return a\n",
    "def kpca(comp,kernel_name,gamma):\n",
    "    a=KernelPCA(n_components=comp,kernel=kernel_name,gamma=gamma)\n",
    "    return a\n",
    "def lda(comp):\n",
    "    a=LinearDiscriminantAnalysis(n_components=comp, priors=None, shrinkage=None,solver='svd', store_covariance=False, tol=0.0001)\n",
    "    return a\n",
    "def dim(dimen,comp,kernel_name,gamma):\n",
    "    if dimen==0:\n",
    "        a=pca(comp)\n",
    "    if dimen==1:\n",
    "        a=kpca(comp,kernel_name,gamma)\n",
    "    if dimen==2:\n",
    "        a=lda(comp)\n",
    "    return a\n",
    "\n",
    "def pca(dimen,kernel_name,gamma,comp,smote,model):\n",
    "    comp=int(comp)\n",
    "    Xs=preprocessing.scale(X)\n",
    "    kpca=dim(dimen,comp,kernel_name,gamma)\n",
    "    #kpca = KernelPCA(n_components=comp,kernel=kernel_name,gamma=gamma)\n",
    "    if dimen==2:\n",
    "        X_transformed = kpca.fit_transform(X)\n",
    "    else:\n",
    "        X_transformed = kpca.fit_transform(X)\n",
    "    X_train, X_test, Y_train, Y_test=nocross(X_transformed,Y)\n",
    "    X_train,X_test,Y_train,Y_test=smoteselector(X_train,X_test,Y_train,Y_test,smote)\n",
    "    mod=modelselector(model)\n",
    "    fitpredict(X_train,Y_train,mod,X_test,Y_test,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T10:54:32.641867Z",
     "start_time": "2018-10-23T10:54:14.467252Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdecbdc2191a48008403696295521507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='dimen', max=2), Dropdown(description='kernel_name', optiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.pca(dimen, kernel_name, gamma, comp, smote, model)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for i in range(0,6):\n",
    "#mod(cross,norstd,smote,featureselect,model,graph)\n",
    "#cross:0 for normal // 1 for 10cross validation\n",
    "#norstd:0 for no effect // 1 for normalize // 2 for standardize\n",
    "#smote:0 for no effect // 1 for smote // 2 for rus\n",
    "#featureselect:0 for no effect // 1 for fcbf // 2 for cfs (takes long time)// 3 for reliefF (takes long time)// 4 for PCA\n",
    "#model:0 for no LR // 1 for ANN // 2 for CRT // 3 for SVCL(SVM) // 4 for SVCP(SVM POLY) // 5 for Random Forest // 6 for DT\n",
    "#run nested loop to print all\n",
    "#mod(0,0,0,5,1,0)\n",
    "#pca(X,Y)\n",
    "from ipywidgets import interact, FloatSlider, Dropdown,IntSlider\n",
    "interact(pca, \n",
    "         dimen=IntSlider(min=0, max=2, step=1, value=1),kernel_name=Dropdown(options=['rbf', 'sigmoid']),gamma=FloatSlider(min=0.001, max=25, step=0.001, value=10),C=FloatSlider(min=0.001, max=10, step=0.001, value=1),comp=FloatSlider(min=1, max=10, step=1, value=5),smote=IntSlider(min=0, max=2, step=1, value=1),model=IntSlider(min=0, max=10, step=1, value=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T10:54:32.649863Z",
     "start_time": "2018-10-23T10:54:32.644868Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    # Convert pandas data into a dict of np arrays.\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                            \n",
    " \n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels\n",
    "def train_linear_classifier_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "    periods = 10\n",
    "    steps_per_period = steps / periods\n",
    "    print(steps_per_period)\n",
    "  \n",
    "  # Create a linear classifier object.\n",
    "    my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)  \n",
    "    linear_classifier = tf.estimator.LinearClassifier(feature_columns=training_examples,optimizer=my_optimizer)\n",
    "  \n",
    "  # Create input functions.\n",
    "    training_input_fn = lambda: my_input_fn(training_examples,training_targets, batch_size=batch_size)\n",
    "    predict_training_input_fn = lambda: my_input_fn(training_examples,training_targets,num_epochs=1,shuffle=False)\n",
    "    predict_validation_input_fn = lambda: my_input_fn(validation_examples, validation_targets, num_epochs=1, shuffle=False)\n",
    "  \n",
    "  # Train the model, but do so inside a loop so that we can periodically assess\n",
    "  # loss metrics.\n",
    "    x,y=training_input_fn()\n",
    "    print(x,y)\n",
    "    print(\"Training model...\")\n",
    "    print(\"LogLoss (on training data):\")\n",
    "    training_log_losses = []\n",
    "    validation_log_losses = []\n",
    "    for period in range (0, periods):\n",
    "    # Train the model, starting from the prior state.\n",
    "        linear_classifier.train(input_fn=training_input_fn,steps=steps_per_period)\n",
    "    # Take a break and compute predictions.    \n",
    "        training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn)\n",
    "        training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n",
    "    \n",
    "        validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
    "        validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n",
    "    \n",
    "        training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n",
    "        validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n",
    "    # Occasionally print the current loss.\n",
    "        print(\"  period %02d : %0.2f\" % (period, training_log_loss))\n",
    "    # Add the loss metrics from this period to our list.\n",
    "        training_log_losses.append(training_log_loss)\n",
    "        validation_log_losses.append(validation_log_loss)\n",
    "    print(\"Model training finished.\")\n",
    "  \n",
    "  # Output a graph of loss metrics over periods.\n",
    "    plt.ylabel(\"LogLoss\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"LogLoss vs. Periods\")\n",
    "    plt.tight_layout()\n",
    "    plt.plot(training_log_losses, label=\"training\")\n",
    "    plt.plot(validation_log_losses, label=\"validation\")\n",
    "    plt.legend()\n",
    "\n",
    "    return linear_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmpxn0wjma5\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\tmpxn0wjma5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000195EEC45F98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "{'ABO': <tf.Tensor 'IteratorGetNext:0' shape=(?,) dtype=int32>, 'ABO_DON': <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=int32>, 'ABO_MAT': <tf.Tensor 'IteratorGetNext:2' shape=(?,) dtype=int64>, 'AGE': <tf.Tensor 'IteratorGetNext:3' shape=(?,) dtype=int64>, 'AGE_DON': <tf.Tensor 'IteratorGetNext:4' shape=(?,) dtype=int64>, 'AGE_MATCH_LEVEL': <tf.Tensor 'IteratorGetNext:6' shape=(?,) dtype=int64>, 'AGE_GROUP': <tf.Tensor 'IteratorGetNext:5' shape=(?,) dtype=int32>, 'ANTICONV_DON': <tf.Tensor 'IteratorGetNext:9' shape=(?,) dtype=int32>, 'ANTIHYPE_DON': <tf.Tensor 'IteratorGetNext:10' shape=(?,) dtype=int32>, 'BLOOD_INF_DON': <tf.Tensor 'IteratorGetNext:11' shape=(?,) dtype=int64>, 'BMI_CALC': <tf.Tensor 'IteratorGetNext:14' shape=(?,) dtype=float64>, 'BUN_DON': <tf.Tensor 'IteratorGetNext:15' shape=(?,) dtype=float64>, 'CARDARREST_NEURO': <tf.Tensor 'IteratorGetNext:16' shape=(?,) dtype=int32>, 'CEREB_VASC': <tf.Tensor 'IteratorGetNext:17' shape=(?,) dtype=int32>, 'CITIZENSHIP': <tf.Tensor 'IteratorGetNext:18' shape=(?,) dtype=int64>, 'CITIZENSHIP_DON': <tf.Tensor 'IteratorGetNext:19' shape=(?,) dtype=int64>, 'COD_CAD_DON': <tf.Tensor 'IteratorGetNext:20' shape=(?,) dtype=int64>, 'CORONARY_ANGIO': <tf.Tensor 'IteratorGetNext:21' shape=(?,) dtype=int64>, 'CREAT_DON': <tf.Tensor 'IteratorGetNext:22' shape=(?,) dtype=float64>, 'CRSMATCH_DONE': <tf.Tensor 'IteratorGetNext:24' shape=(?,) dtype=int32>, 'DAYS_STAT1': <tf.Tensor 'IteratorGetNext:26' shape=(?,) dtype=int64>, 'DAYS_STAT1A': <tf.Tensor 'IteratorGetNext:27' shape=(?,) dtype=int64>, 'DAYS_STAT1B': <tf.Tensor 'IteratorGetNext:28' shape=(?,) dtype=int64>, 'DAYS_STAT2': <tf.Tensor 'IteratorGetNext:29' shape=(?,) dtype=int64>, 'DAYSWAIT_CHRON': <tf.Tensor 'IteratorGetNext:25' shape=(?,) dtype=int64>, 'DDAVP_DON': <tf.Tensor 'IteratorGetNext:30' shape=(?,) dtype=int32>, 'DEATH_CIRCUM_DON': <tf.Tensor 'IteratorGetNext:31' shape=(?,) dtype=int64>, 'DEATH_MECH_DON': <tf.Tensor 'IteratorGetNext:32' shape=(?,) dtype=int64>, 'DIAB': <tf.Tensor 'IteratorGetNext:33' shape=(?,) dtype=int64>, 'DIABETES_DON': <tf.Tensor 'IteratorGetNext:34' shape=(?,) dtype=int32>, 'DIAG': <tf.Tensor 'IteratorGetNext:35' shape=(?,) dtype=int64>, 'DIAL_AFTER_LIST': <tf.Tensor 'IteratorGetNext:36' shape=(?,) dtype=int32>, 'DIAL_PRIOR_TX': <tf.Tensor 'IteratorGetNext:37' shape=(?,) dtype=int32>, 'DIAL_TY_TCR': <tf.Tensor 'IteratorGetNext:38' shape=(?,) dtype=int64>, 'DISTANCE': <tf.Tensor 'IteratorGetNext:39' shape=(?,) dtype=float64>, 'DON_RETYP': <tf.Tensor 'IteratorGetNext:40' shape=(?,) dtype=int32>, 'ECMO_TCR': <tf.Tensor 'IteratorGetNext:43' shape=(?,) dtype=int64>, 'EDUCATION': <tf.Tensor 'IteratorGetNext:45' shape=(?,) dtype=int64>, 'END_STAT': <tf.Tensor 'IteratorGetNext:46' shape=(?,) dtype=int64>, 'ETHCAT': <tf.Tensor 'IteratorGetNext:47' shape=(?,) dtype=int64>, 'ETHCAT_DON': <tf.Tensor 'IteratorGetNext:48' shape=(?,) dtype=int64>, 'ETHCAT_MATCH': <tf.Tensor 'IteratorGetNext:49' shape=(?,) dtype=int64>, 'ETHNICITY': <tf.Tensor 'IteratorGetNext:50' shape=(?,) dtype=int64>, 'FUNC_STAT_TCR': <tf.Tensor 'IteratorGetNext:51' shape=(?,) dtype=int64>, 'FUNC_STAT_TRR': <tf.Tensor 'IteratorGetNext:52' shape=(?,) dtype=int64>, 'GENDER': <tf.Tensor 'IteratorGetNext:53' shape=(?,) dtype=int32>, 'GENDER_DON': <tf.Tensor 'IteratorGetNext:54' shape=(?,) dtype=int32>, 'GENDER_MATCH': <tf.Tensor 'IteratorGetNext:55' shape=(?,) dtype=int64>, 'HBV_CORE_DON': <tf.Tensor 'IteratorGetNext:56' shape=(?,) dtype=int32>, 'HCV_SEROSTATUS': <tf.Tensor 'IteratorGetNext:57' shape=(?,) dtype=int32>, 'HEMO_PA_DIA_TCR': <tf.Tensor 'IteratorGetNext:58' shape=(?,) dtype=float64>, 'HEMO_SYS_TCR': <tf.Tensor 'IteratorGetNext:60' shape=(?,) dtype=float64>, 'HEP_C_ANTI_DON': <tf.Tensor 'IteratorGetNext:62' shape=(?,) dtype=int32>, 'HGT_CM_TCR': <tf.Tensor 'IteratorGetNext:63' shape=(?,) dtype=int64>, 'HIST_CANCER_DON': <tf.Tensor 'IteratorGetNext:64' shape=(?,) dtype=int32>, 'HIST_CIG_DON': <tf.Tensor 'IteratorGetNext:65' shape=(?,) dtype=int32>, 'HIST_DIABETES_DON': <tf.Tensor 'IteratorGetNext:66' shape=(?,) dtype=int64>, 'HIST_HYPERTENS_DON': <tf.Tensor 'IteratorGetNext:67' shape=(?,) dtype=int32>, 'HIST_OTH_DRUG_DON': <tf.Tensor 'IteratorGetNext:68' shape=(?,) dtype=int32>, 'HLAMAT': <tf.Tensor 'IteratorGetNext:69' shape=(?,) dtype=int64>, 'HLAMIS': <tf.Tensor 'IteratorGetNext:70' shape=(?,) dtype=int64>, 'IABP_TCR': <tf.Tensor 'IteratorGetNext:71' shape=(?,) dtype=int64>, 'IMPL_DEFIBRIL': <tf.Tensor 'IteratorGetNext:73' shape=(?,) dtype=int32>, 'INFECT_IV_DRUG_TRR': <tf.Tensor 'IteratorGetNext:74' shape=(?,) dtype=int32>, 'INIT_STAT': <tf.Tensor 'IteratorGetNext:75' shape=(?,) dtype=int64>, 'INOTROP_AGENTS': <tf.Tensor 'IteratorGetNext:78' shape=(?,) dtype=int32>, 'INOTROP_VASO_DIA_TCR': <tf.Tensor 'IteratorGetNext:79' shape=(?,) dtype=int32>, 'INOTROP_VASO_SYS_TCR': <tf.Tensor 'IteratorGetNext:81' shape=(?,) dtype=int32>, 'INOTROPES_TCR': <tf.Tensor 'IteratorGetNext:76' shape=(?,) dtype=int64>, 'LIFE_SUP': <tf.Tensor 'IteratorGetNext:83' shape=(?,) dtype=int32>, 'LIFE_SUP_TCR': <tf.Tensor 'IteratorGetNext:84' shape=(?,) dtype=int32>, 'LIFE_SUP_TRR': <tf.Tensor 'IteratorGetNext:85' shape=(?,) dtype=int32>, 'MALIG': <tf.Tensor 'IteratorGetNext:86' shape=(?,) dtype=int32>, 'MALIG_TCR': <tf.Tensor 'IteratorGetNext:87' shape=(?,) dtype=int32>, 'MED_COND_TRR': <tf.Tensor 'IteratorGetNext:88' shape=(?,) dtype=int64>, 'NUM_PREV_TX': <tf.Tensor 'IteratorGetNext:89' shape=(?,) dtype=int64>, 'OTH_LIFE_SUP_TCR': <tf.Tensor 'IteratorGetNext:90' shape=(?,) dtype=int64>, 'PREV_MALIG': <tf.Tensor 'IteratorGetNext:92' shape=(?,) dtype=int32>, 'PREV_TX': <tf.Tensor 'IteratorGetNext:93' shape=(?,) dtype=int32>, 'PRI_PAYMENT_TCR': <tf.Tensor 'IteratorGetNext:94' shape=(?,) dtype=int64>, 'PRI_PAYMENT_TRR': <tf.Tensor 'IteratorGetNext:95' shape=(?,) dtype=int64>, 'PROC_TY_HR': <tf.Tensor 'IteratorGetNext:96' shape=(?,) dtype=int64>, 'PULM_CATH_DON': <tf.Tensor 'IteratorGetNext:97' shape=(?,) dtype=int32>, 'PULM_INF_DON': <tf.Tensor 'IteratorGetNext:98' shape=(?,) dtype=int64>, 'REGION': <tf.Tensor 'IteratorGetNext:99' shape=(?,) dtype=int64>, 'SGPT_DON': <tf.Tensor 'IteratorGetNext:100' shape=(?,) dtype=float64>, 'SHARE_TY': <tf.Tensor 'IteratorGetNext:101' shape=(?,) dtype=int64>, 'TATTOOS': <tf.Tensor 'IteratorGetNext:102' shape=(?,) dtype=int32>, 'TBILI_DON': <tf.Tensor 'IteratorGetNext:103' shape=(?,) dtype=float64>, 'TCR_DGN': <tf.Tensor 'IteratorGetNext:104' shape=(?,) dtype=int64>, 'THORACIC_DGN': <tf.Tensor 'IteratorGetNext:105' shape=(?,) dtype=int64>, 'URINE_INF_DON': <tf.Tensor 'IteratorGetNext:106' shape=(?,) dtype=int64>, 'VASODIL_DON': <tf.Tensor 'IteratorGetNext:107' shape=(?,) dtype=int32>, 'VDRL_DON': <tf.Tensor 'IteratorGetNext:108' shape=(?,) dtype=int32>, 'VENT_SUPPORT_AFTER_LIST': <tf.Tensor 'IteratorGetNext:111' shape=(?,) dtype=int32>, 'VENTILATOR_TCR': <tf.Tensor 'IteratorGetNext:109' shape=(?,) dtype=int64>, 'WGT_KG_DON_CALC': <tf.Tensor 'IteratorGetNext:113' shape=(?,) dtype=float64>, 'WGT_KG_TCR': <tf.Tensor 'IteratorGetNext:114' shape=(?,) dtype=float64>, 'AMAT': <tf.Tensor 'IteratorGetNext:7' shape=(?,) dtype=int64>, 'AMIS': <tf.Tensor 'IteratorGetNext:8' shape=(?,) dtype=int64>, 'BMAT': <tf.Tensor 'IteratorGetNext:12' shape=(?,) dtype=int64>, 'BMIS': <tf.Tensor 'IteratorGetNext:13' shape=(?,) dtype=int64>, 'CREAT_TRR': <tf.Tensor 'IteratorGetNext:23' shape=(?,) dtype=float64>, 'DRMAT': <tf.Tensor 'IteratorGetNext:41' shape=(?,) dtype=int64>, 'DRMIS': <tf.Tensor 'IteratorGetNext:42' shape=(?,) dtype=int64>, 'ECMO_TRR': <tf.Tensor 'IteratorGetNext:44' shape=(?,) dtype=int64>, 'HEMO_PA_DIA_TRR': <tf.Tensor 'IteratorGetNext:59' shape=(?,) dtype=float64>, 'HEMO_SYS_TRR': <tf.Tensor 'IteratorGetNext:61' shape=(?,) dtype=int64>, 'IABP_TRR': <tf.Tensor 'IteratorGetNext:72' shape=(?,) dtype=int64>, 'INOTROP_VASO_DIA_TRR': <tf.Tensor 'IteratorGetNext:80' shape=(?,) dtype=int32>, 'INOTROP_VASO_SYS_TRR': <tf.Tensor 'IteratorGetNext:82' shape=(?,) dtype=int32>, 'INOTROPES_TRR': <tf.Tensor 'IteratorGetNext:77' shape=(?,) dtype=int64>, 'OTH_LIFE_SUP_TRR': <tf.Tensor 'IteratorGetNext:91' shape=(?,) dtype=int64>, 'VENT_SUPPORT_TRR': <tf.Tensor 'IteratorGetNext:112' shape=(?,) dtype=int32>, 'VENTILATOR_TRR': <tf.Tensor 'IteratorGetNext:110' shape=(?,) dtype=int64>} Tensor(\"IteratorGetNext:115\", shape=(?,), dtype=int64)\n",
      "Training model...\n",
      "LogLoss (on training data):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-4ff093386fad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mtraining_targets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mvalidation_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     validation_targets=Y_test)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-508ad9471bc6>\u001b[0m in \u001b[0;36mtrain_linear_classifier_model\u001b[1;34m(learning_rate, steps, batch_size, training_examples, training_targets, validation_examples, validation_targets)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mperiod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiods\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# Train the model, starting from the prior state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mlinear_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_input_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_period\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;31m# Take a break and compute predictions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mtraining_probabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict_training_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1179\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1181\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1209\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m-> 1211\u001b[1;33m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[0;32m   1212\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\linear.py\u001b[0m in \u001b[0;36m_model_fn\u001b[1;34m(features, labels, mode, config)\u001b[0m\n\u001b[0;32m    333\u001b[0m           \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m           \u001b[0mhead\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m           \u001b[0mfeature_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_columns\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1574\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[0;32m   1575\u001b[0m                          \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1576\u001b[1;33m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[0;32m   1577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=10)\n",
    "linear_classifier = train_linear_classifier_model(\n",
    "    learning_rate=0.000005,\n",
    "    steps=500,\n",
    "    batch_size=20,\n",
    "    training_examples=X_train,\n",
    "    training_targets=Y_train,\n",
    "    validation_examples=X_test,\n",
    "    validation_targets=Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
